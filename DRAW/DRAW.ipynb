{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to VAE.\n",
    "\n",
    "Three key differences:\n",
    "\n",
    "encoder,decoder: RNN\n",
    "\n",
    "decoders' outputs are successively added to the distribution that will ultimately generate the data.\n",
    "\n",
    "dynamically updated attention mechanism, decide where to read, where to write, what towrite.\n",
    "\n",
    "$$x_t=x-\\sigma(c_{t-1})$$\n",
    "$$r_t=\\text{read}(x_t,\\hat{x_t},h_{t-1}^\\text{dec})$$\n",
    "$$h_t^{\\text{enc}} = \\text{RNN}^{\\text{enc}}(h_{t-1}^{\\text{enc}},[r_t,h_{t-1}^{\\text{dec}}])$$\n",
    "$$z_t\\sim Q(z_t|h_t^{\\text{enc}})$$\n",
    "$$h_t^{\\text{dec}}=\\text{RNN}^{\\text{dec}}(h_{t-1}^{\\text{dec}},z_t)$$\n",
    "$$c_t=c_{t-1}+\\text{write}(h_t^{\\text{dec}})$$\n",
    "\n",
    "VAE loss: KL divergence is cumulated through time step T.\n",
    "\n",
    "Selective attention model: similar to attention model with gaussian smooth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/czm0/draw_pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     6,
     33,
     37,
     45,
     62,
     81,
     102,
     112,
     157
    ]
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from utility import *\n",
    "import torch.functional as F\n",
    "\n",
    "class DrawModel(nn.Module):\n",
    "    def __init__(self,T,A,B,z_size,N,dec_size,enc_size):\n",
    "        super(DrawModel,self).__init__()\n",
    "        self.T = T\n",
    "        # self.batch_size = batch_size\n",
    "        self.A = A\n",
    "        self.B = B\n",
    "        self.z_size = z_size\n",
    "        self.N = N\n",
    "        self.dec_size = dec_size\n",
    "        self.enc_size = enc_size\n",
    "        self.cs = [0] * T\n",
    "        self.logsigmas,self.sigmas,self.mus = [0] * T,[0] * T,[0] * T\n",
    "\n",
    "        self.encoder = nn.LSTMCell(2 * N * N + dec_size, enc_size)\n",
    "        self.encoder_gru = nn.GRUCell(2 * N * N + dec_size, enc_size)\n",
    "        self.mu_linear = nn.Linear(dec_size, z_size)\n",
    "        self.sigma_linear = nn.Linear(dec_size, z_size)\n",
    "\n",
    "        self.decoder = nn.LSTMCell(z_size,dec_size)\n",
    "        self.decoder_gru = nn.GRUCell(z_size,dec_size)\n",
    "        self.dec_linear = nn.Linear(dec_size,5)\n",
    "        self.dec_w_linear = nn.Linear(dec_size,N*N)\n",
    "\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "\n",
    "\n",
    "    def normalSample(self):\n",
    "        return Variable(torch.randn(self.batch_size,self.z_size))\n",
    "\n",
    "    # correct\n",
    "    def compute_mu(self,g,rng,delta):\n",
    "        rng_t,delta_t = align(rng,delta)\n",
    "        tmp = (rng_t - self.N / 2 - 0.5) * delta_t\n",
    "        tmp_t,g_t = align(tmp,g)\n",
    "        mu = tmp_t + g_t\n",
    "        return mu\n",
    "\n",
    "    # correct\n",
    "    def filterbank(self,gx,gy,sigma2,delta):\n",
    "        rng = Variable(torch.arange(0,self.N).view(1,-1))\n",
    "        mu_x = self.compute_mu(gx,rng,delta)\n",
    "        mu_y = self.compute_mu(gy,rng,delta)\n",
    "\n",
    "        a = Variable(torch.arange(0,self.A).view(1,1,-1))\n",
    "        b = Variable(torch.arange(0,self.B).view(1,1,-1))\n",
    "\n",
    "        mu_x = mu_x.view(-1,self.N,1)\n",
    "        mu_y = mu_y.view(-1,self.N,1)\n",
    "        sigma2 = sigma2.view(-1,1,1)\n",
    "\n",
    "        Fx = self.filterbank_matrices(a,mu_x,sigma2)\n",
    "        Fy = self.filterbank_matrices(b,mu_y,sigma2)\n",
    "\n",
    "        return Fx,Fy\n",
    "\n",
    "    def forward(self,x):\n",
    "        self.batch_size = x.size()[0]\n",
    "        h_dec_prev = Variable(torch.zeros(self.batch_size,self.dec_size))\n",
    "        h_enc_prev = Variable(torch.zeros(self.batch_size, self.enc_size))\n",
    "\n",
    "        enc_state = Variable(torch.zeros(self.batch_size,self.enc_size))\n",
    "        dec_state = Variable(torch.zeros(self.batch_size, self.dec_size))\n",
    "        for t in xrange(self.T):\n",
    "            c_prev = Variable(torch.zeros(self.batch_size,self.A * self.B)) if t == 0 else self.cs[t-1]\n",
    "            x_hat = x - self.sigmoid(c_prev)     # 3\n",
    "            r_t = self.read(x,x_hat,h_dec_prev)\n",
    "            h_enc_prev,enc_state = self.encoder(torch.cat((r_t,h_dec_prev),1),(h_enc_prev,enc_state))\n",
    "            # h_enc = self.encoder_gru(torch.cat((r_t,h_dec_prev),1),h_enc_prev)\n",
    "            z,self.mus[t],self.logsigmas[t],self.sigmas[t] = self.sampleQ(h_enc_prev)\n",
    "            h_dec,dec_state = self.decoder(z, (h_dec_prev, dec_state))\n",
    "            # h_dec = self.decoder_gru(z, h_dec_prev)\n",
    "            self.cs[t] = c_prev + self.write(h_dec)\n",
    "            h_dec_prev = h_dec\n",
    "\n",
    "    def loss(self,x):\n",
    "        self.forward(x)\n",
    "        criterion = nn.BCELoss()\n",
    "        x_recons = self.sigmoid(self.cs[-1])\n",
    "        Lx = criterion(x_recons,x) * self.A * self.B\n",
    "        Lz = 0\n",
    "        kl_terms = [0] * T\n",
    "        for t in xrange(self.T):\n",
    "            mu_2 = self.mus[t] * self.mus[t]\n",
    "            sigma_2 = self.sigmas[t] * self.sigmas[t]\n",
    "            logsigma = self.logsigmas[t]\n",
    "            # Lz += (0.5 * (mu_2 + sigma_2 - 2 * logsigma))    # 11\n",
    "            kl_terms[t] = 0.5 * torch.sum(mu_2+sigma_2-2 * logsigma,1) - self.T * 0.5\n",
    "            Lz += kl_terms[t]\n",
    "        # Lz -= self.T / 2\n",
    "        Lz = torch.mean(Lz)    ####################################################\n",
    "        loss = Lz + Lx    # 12\n",
    "        return loss\n",
    "\n",
    "\n",
    "    # correct\n",
    "    def filterbank_matrices(self,a,mu_x,sigma2,epsilon=1e-9):\n",
    "        t_a,t_mu_x = align(a,mu_x)\n",
    "        temp = t_a - t_mu_x\n",
    "        temp,t_sigma = align(temp,sigma2)\n",
    "        temp = temp / (t_sigma * 2)\n",
    "        F = torch.exp(-torch.pow(temp,2))\n",
    "        F = F / (F.sum(2,True).expand_as(F) + epsilon)\n",
    "        return F\n",
    "\n",
    "    #correct\n",
    "    def attn_window(self,h_dec):\n",
    "        params = self.dec_linear(h_dec)\n",
    "        gx_,gy_,log_sigma_2,log_delta,log_gamma = params.split(1,1)  #21\n",
    "\n",
    "        # gx_ = Variable(torch.ones(4,1))\n",
    "        # gy_ = Variable(torch.ones(4, 1) * 2)\n",
    "        # log_sigma_2 = Variable(torch.ones(4, 1) * 3)\n",
    "        # log_delta = Variable(torch.ones(4, 1) * 4)\n",
    "        # log_gamma = Variable(torch.ones(4, 1) * 5)\n",
    "\n",
    "        gx = (self.A + 1) / 2 * (gx_ + 1)    # 22\n",
    "        gy = (self.B + 1) / 2 * (gy_ + 1)    # 23\n",
    "        delta = (max(self.A,self.B) - 1) / (self.N - 1) * torch.exp(log_delta)  # 24\n",
    "        sigma2 = torch.exp(log_sigma_2)\n",
    "        gamma = torch.exp(log_gamma)\n",
    "\n",
    "        return self.filterbank(gx,gy,sigma2,delta),gamma\n",
    "    # correct\n",
    "    def read(self,x,x_hat,h_dec_prev):\n",
    "        (Fx,Fy),gamma = self.attn_window(h_dec_prev)\n",
    "        def filter_img(img,Fx,Fy,gamma,A,B,N):\n",
    "            Fxt = Fx.transpose(2,1)\n",
    "            img = img.view(-1,B,A)\n",
    "            # img = img.transpose(2,1)\n",
    "            # glimpse = matmul(Fy,matmul(img,Fxt))\n",
    "            glimpse = Fy.bmm(img.bmm(Fxt))\n",
    "            glimpse = glimpse.view(-1,N*N)\n",
    "            return glimpse * gamma.view(-1,1).expand_as(glimpse)\n",
    "        x = filter_img(x,Fx,Fy,gamma,self.A,self.B,self.N)\n",
    "        x_hat = filter_img(x_hat,Fx,Fy,gamma,self.A,self.B,self.N)\n",
    "        return torch.cat((x,x_hat),1)\n",
    "\n",
    "    # correct\n",
    "    def write(self,h_dec=0):\n",
    "        w = self.dec_w_linear(h_dec)\n",
    "        w = w.view(self.batch_size,self.N,self.N)\n",
    "        # w = Variable(torch.ones(4,5,5) * 3)\n",
    "        # self.batch_size = 4\n",
    "        (Fx,Fy),gamma = self.attn_window(h_dec)\n",
    "        Fyt = Fy.transpose(2,1)\n",
    "        # wr = matmul(Fyt,matmul(w,Fx))\n",
    "        wr = Fyt.bmm(w.bmm(Fx))\n",
    "        wr = wr.view(self.batch_size,self.A*self.B)\n",
    "        return wr / gamma.view(-1,1).expand_as(wr)\n",
    "\n",
    "    def sampleQ(self,h_enc):\n",
    "        e = self.normalSample()\n",
    "        # mu_sigma = self.mu_sigma_linear(h_enc)\n",
    "        # mu = mu_sigma[:, :self.z_size]\n",
    "        # log_sigma = mu_sigma[:, self.z_size:]\n",
    "        mu = self.mu_linear(h_enc)           # 1\n",
    "        log_sigma = self.sigma_linear(h_enc) # 2\n",
    "        sigma = torch.exp(log_sigma)\n",
    "\n",
    "        return mu + sigma * e , mu , log_sigma, sigma\n",
    "\n",
    "    def generate(self,batch_size=64):\n",
    "        self.batch_size = batch_size\n",
    "        h_dec_prev = Variable(torch.zeros(self.batch_size,self.dec_size),volatile = True)\n",
    "        dec_state = Variable(torch.zeros(self.batch_size, self.dec_size),volatile = True)\n",
    "\n",
    "        for t in xrange(self.T):\n",
    "            c_prev = Variable(torch.zeros(self.batch_size, self.A * self.B)) if t == 0 else self.cs[t - 1]\n",
    "            z = self.normalSample()\n",
    "            h_dec, dec_state = self.decoder(z, (h_dec_prev, dec_state))\n",
    "            self.cs[t] = c_prev + self.write(h_dec)\n",
    "            h_dec_prev = h_dec\n",
    "        imgs = []\n",
    "        for img in self.cs:\n",
    "            imgs.append(self.sigmoid(img).cpu().data.numpy())\n",
    "        return imgs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# model = DrawModel(10,5,5,10,5,128,128)\n",
    "# x = Variable(torch.ones(4,25))\n",
    "# x_hat = Variable(torch.ones(4,25)*2)\n",
    "# r = model.write()\n",
    "# print r\n",
    "# g = Variable(torch.ones(4,1))\n",
    "# delta = Variable(torch.ones(4,1)  * 3)\n",
    "# sigma = Variable(torch.ones(4,1))\n",
    "# rng = Variable(torch.arange(0,5).view(1,-1))\n",
    "# mu_x = model.compute_mu(g,rng,delta)\n",
    "# a = Variable(torch.arange(0,5).view(1,1,-1))\n",
    "# mu_x = mu_x.view(-1,5,1)\n",
    "# sigma = sigma.view(-1,1,1)\n",
    "# F = model.filterbank_matrices(a,mu_x,sigma)\n",
    "# print F\n",
    "# def test_normalSample():\n",
    "#     print model.normalSample()\n",
    "#\n",
    "# def test_write():\n",
    "#     h_dec = Variable(torch.zeros(8,128))\n",
    "#     model.write(h_dec)\n",
    "#\n",
    "# def test_read():\n",
    "#     x = Variable(torch.zeros(8,28*28))\n",
    "#     x_hat = Variable((torch.zeros(8,28*28)))\n",
    "#     h_dec = Variable(torch.zeros(8, 128))\n",
    "#     model.read(x,x_hat,h_dec)\n",
    "#\n",
    "# def test_loss():\n",
    "#     x = Variable(torch.zeros(8,28*28))\n",
    "#     loss = model.loss(x)\n",
    "#     print loss\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
